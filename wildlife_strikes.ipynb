import pandas as pd




df = pd.read_csv("STRIKE_REPORTS.csv", low_memory=False)

df.drop(columns=["INDEX_NR"], inplace=True)
df.drop(columns=["LOCATION"], inplace=True)
df.drop(columns=["ENROUTE_STATE"], inplace=True)
df.drop(columns=["REG"], inplace=True)
df.drop(columns=["FLT"], inplace=True)
df.drop(columns=["AIRCRAFT"], inplace=True)
df.drop(columns=["AMA"], inplace=True)
df.drop(columns=["AMO"], inplace=True)
df.drop(columns=["EMA"], inplace=True)
df.drop(columns=["EMO"], inplace=True)
df.drop(columns=["AC_CLASS"], inplace=True)
df.drop(columns=["AC_MASS"], inplace=True)
df.drop(columns=["TYPE_ENG"], inplace=True)
df.drop(columns=["NUM_ENGS"], inplace=True)
df.drop(columns=["ENG_1_POS"], inplace=True)
df.drop(columns=["ENG_2_POS"], inplace=True)
df.drop(columns=["ENG_3_POS"], inplace=True)
df.drop(columns=["ENG_4_POS"], inplace=True)
df.drop(columns=["AOS"], inplace=True)
df.drop(columns=["COST_REPAIRS"], inplace=True)
df.drop(columns=["COST_OTHER"], inplace=True)
df.drop(columns=["COST_REPAIRS_INFL_ADJ"], inplace=True)
df.drop(columns=["COST_OTHER_INFL_ADJ"], inplace=True)
df.drop(columns=["INGESTED_OTHER"], inplace=True)
df.drop(columns=["OTHER_SPECIFY"], inplace=True)
df.drop(columns=["EFFECT"], inplace=True)
df.drop(columns=["EFFECT_OTHER"], inplace=True)
df.drop(columns=["BIRD_BAND_NUMBER"], inplace=True)
df.drop(columns=["REMARKS"], inplace=True)
df.drop(columns=["REMAINS_COLLECTED"], inplace=True)
df.drop(columns=["REMAINS_SENT"], inplace=True)
df.drop(columns=["NUM_SEEN"], inplace=True)
df.drop(columns=["NUM_STRUCK"], inplace=True)
df.drop(columns=["NR_INJURIES"], inplace=True)
df.drop(columns=["NR_FATALITIES"], inplace=True)
df.drop(columns=["COMMENTS"], inplace=True)
df.drop(columns=["REPORTED_NAME"], inplace=True)
df.drop(columns=["REPORTED_TITLE"], inplace=True)
df.drop(columns=["SOURCE"], inplace=True)
df.drop(columns=["PERSON"], inplace=True)
df.drop(columns=["LUPDATE"], inplace=True)
df.drop(columns=["TRANSFER"], inplace=True)
df.drop(columns=["WARNED"], inplace=True)
df.drop(columns=["AIRPORT_ID"], inplace=True)
df.drop(columns=["AIRPORT"], inplace=True)
df.drop(columns=["SPECIES_ID"], inplace=True)
df.drop(columns=["SIZE"], inplace=True)
df.drop(columns=["FAAREGION"], inplace=True)
df.drop(columns=["OPID"], inplace=True)
df.drop(columns=["RUNWAY"], inplace=True)
df.drop(columns=["OPERATOR"], inplace=True)
df.drop(columns=["DISTANCE"], inplace=True)
df.drop(columns=["SPEED"], inplace=True)
df.drop(columns=["PRECIPITATION"], inplace=True)
df.drop(columns=["DAMAGE_LEVEL"], inplace=True)

cols_to_drop = ['STR_RAD', 'DAM_RAD', 'STR_WINDSHLD', 'DAM_WINDSHLD', 'STR_NOSE', 'DAM_NOSE','STR_ENG1',
                'DAM_ENG1', 'ING_ENG1','STR_ENG2','DAM_ENG2','STR_RAD','DAM_RAD','STR_WINDSHLD',
                'DAM_WINDSHLD','STR_NOSE','DAM_NOSE','STR_ENG1','DAM_ENG1','ING_ENG1','STR_ENG2',
                'DAM_ENG2','ING_ENG2','STR_ENG3','DAM_ENG3','ING_ENG3','STR_ENG4','STR_RAD','DAM_RAD',
                'STR_WINDSHLD','DAM_WINDSHLD','STR_NOSE','DAM_NOSE','STR_ENG1','DAM_ENG1','ING_ENG1',
                'STR_ENG2','DAM_ENG2','ING_ENG2','STR_ENG3','DAM_ENG3','ING_ENG3','STR_ENG4','DAM_ENG4',
                'ING_ENG4','STR_PROP','DAM_PROP','STR_LGHTS', 'STR_LG', 'DAM_OTHER', 'DAM_LG', 'DAM_LGHTS',
                'DAM_FUSE', 'DAM_WING_ROT', 'STR_OTHER', 'STR_FUSE', 'DAM_PROP', 'DAM_TAIL', 'STR_PROP', 'STR_TAIL', 'STR_WING_ROT']

# Drop the specified columns
df.drop(columns=cols_to_drop, inplace=True)


# Dropping Rows with empty values in valuable categories

df.dropna(subset=['HEIGHT'], inplace=True)
df.dropna(subset=['TIME'], inplace=True)
df.dropna(subset=['LATITUDE'], inplace=True)
df.dropna(subset=['LONGITUDE'], inplace=True)


df['TIME'] = df['TIME'].apply(lambda x: int(x.split(':')[0]) * 60 + int(x.split(':')[1]))
df['INCIDENT_DATE'] = pd.to_datetime(df['INCIDENT_DATE']).astype(int) / 10**9  # Convert to Unix timestamp in seconds


from sklearn.preprocessing import LabelEncoder

# Instantiate LabelEncoder
label_encoder_1 = LabelEncoder()
label_encoder_2 = LabelEncoder()
label_encoder_3 = LabelEncoder()
label_encoder_4 = LabelEncoder()
label_encoder_5 = LabelEncoder()

# Encode the species column
df['SPECIES_ENCODED'] = label_encoder_1.fit_transform(df['SPECIES'])
df.drop(columns=["SPECIES"], inplace=True)

# Encode the PHASE_OF_FLIGHT column
df['PHASE_OF_FLIGHT_ENCODED'] = label_encoder_3.fit_transform(df['PHASE_OF_FLIGHT'])
df.drop(columns=["PHASE_OF_FLIGHT"], inplace=True)

# Encode the TIME_OF_DAY column
df['TIME_OF_DAY_ENCODED'] = label_encoder_2.fit_transform(df['TIME_OF_DAY'])
df.drop(columns=["TIME_OF_DAY"], inplace=True)

# Encode the STATE column
df['STATE_ENCODED'] = label_encoder_4.fit_transform(df['STATE'])
df.drop(columns=["STATE"], inplace=True)


# Encode the SKY column
df['SKY_ENCODED'] = label_encoder_5.fit_transform(df['SKY'])
df.drop(columns=["SKY"], inplace=True)
'''
# Combine latitude and longitude into a single feature
df['LOCATION'] = list(zip(df['LATITUDE'], df['LONGITUDE']))

# Drop the original LATITUDE and LONGITUDE columns
df.drop(['LATITUDE', 'LONGITUDE'], axis=1, inplace=True)
'''
print(df)
# Retrieve the mapping between original labels and encoded labels
label_mapping1 = dict(zip(label_encoder_1.classes_, label_encoder_1.transform(label_encoder_1.classes_)))
label_mapping2 = dict(zip(label_encoder_2.classes_, label_encoder_2.transform(label_encoder_2.classes_)))
label_mapping3 = dict(zip(label_encoder_3.classes_, label_encoder_3.transform(label_encoder_3.classes_)))
label_mapping4 = dict(zip(label_encoder_4.classes_, label_encoder_4.transform(label_encoder_4.classes_)))
label_mapping5 = dict(zip(label_encoder_5.classes_, label_encoder_5.transform(label_encoder_5.classes_)))
# Print the label mapping
print(label_mapping1)
print(label_mapping2)
print(label_mapping3)
print(label_mapping4)
print(label_mapping5)


# Count the number of NaN values in each column
nan_count_per_column = df.isna().sum()

# Print the result
print(nan_count_per_column)
print(df.shape)



from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Splitting the data into features and target variable
X = df.drop(columns=['INDICATED_DAMAGE'])
y = df['INDICATED_DAMAGE']

# Splitting the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize Random Forest Classifier
rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)

# Training the model
rf_classifier.fit(X_train, y_train)

# Making predictions
y_pred = rf_classifier.predict(X_test)

# Model evaluation
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)



from sklearn.metrics import classification_report, confusion_matrix

# Confusion Matrix
conf_matrix = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:\n", conf_matrix)

# Classification Report
class_report = classification_report(y_test, y_pred)
print("Classification Report:\n", class_report)

# Feature Importance
feature_importances = rf_classifier.feature_importances_
feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)
print("Feature Importance:\n", feature_importance_df)



from sklearn.svm import SVC

# Initialize Support Vector Classifier
svm_classifier = SVC(kernel='rbf', random_state=42)

# Training the SVM model
svm_classifier.fit(X_train, y_train)

# Making predictions with SVM
svm_y_pred = svm_classifier.predict(X_test)

# Model evaluation for SVM
svm_accuracy = accuracy_score(y_test, svm_y_pred)
print("SVM Accuracy:", svm_accuracy)



from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier

# Base Random Forest Classifier
base_rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)

# Bagging Classifier
bagging_classifier = BaggingClassifier(base_rf_classifier, n_estimators=100, random_state=42)

# Pasting Classifier
pasting_classifier = BaggingClassifier(base_rf_classifier, n_estimators=100, random_state=42, bootstrap=False)

# AdaBoost Classifier
base_dt_classifier = DecisionTreeClassifier(max_depth=1, random_state=42)
adaboost_classifier = AdaBoostClassifier(base_dt_classifier, n_estimators=100, random_state=42)



# Train and evaluate Bagging Classifier
bagging_classifier.fit(X_train, y_train)
bagging_accuracy = bagging_classifier.score(X_test, y_test)
print("Bagging Classifier Accuracy:", bagging_accuracy)

# Train and evaluate Pasting Classifier
pasting_classifier.fit(X_train, y_train)
pasting_accuracy = pasting_classifier.score(X_test, y_test)
print("Pasting Classifier Accuracy:", pasting_accuracy)


# Train and evaluate AdaBoost Classifier
adaboost_classifier.fit(X_train, y_train)
adaboost_accuracy = adaboost_classifier.score(X_test, y_test)
print("AdaBoost Classifier Accuracy:", adaboost_accuracy)
